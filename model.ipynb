{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4005971232.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    from keras.preprocessing.image import ImageDataGenerator import  load_img\u001b[0m\n\u001b[1;37m                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator import  load_img\n",
    "import warnings\n",
    "#image loading\n",
    "img=load_img(r\"0.jpg\")\n",
    "\n",
    "print(type(img))\n",
    "print(img.format)\n",
    "print(img.mode)\n",
    "print(img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the dataset\n",
    "train_data_dir = 'path/to/training/data'\n",
    "val_data_dir = 'path/to/validation/data'\n",
    "test_data_dir = 'path/to/testing/data'\n",
    "\n",
    "# Set the image dimensions and batch size\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'path/to/training/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m train_datagen \u001b[39m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m      3\u001b[0m     rescale\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m,\n\u001b[0;32m      4\u001b[0m     shear_range\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[0;32m      5\u001b[0m     zoom_range\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[0;32m      6\u001b[0m     horizontal_flip\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m val_datagen \u001b[39m=\u001b[39m ImageDataGenerator(rescale\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m train_generator \u001b[39m=\u001b[39m train_datagen\u001b[39m.\u001b[39;49mflow_from_directory(\n\u001b[0;32m     11\u001b[0m     train_data_dir,\n\u001b[0;32m     12\u001b[0m     target_size\u001b[39m=\u001b[39;49m(img_width, img_height),\n\u001b[0;32m     13\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m     14\u001b[0m     class_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcategorical\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     16\u001b[0m val_generator \u001b[39m=\u001b[39m val_datagen\u001b[39m.\u001b[39mflow_from_directory(\n\u001b[0;32m     17\u001b[0m     val_data_dir,\n\u001b[0;32m     18\u001b[0m     target_size\u001b[39m=\u001b[39m(img_width, img_height),\n\u001b[0;32m     19\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m     20\u001b[0m     class_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m test_generator \u001b[39m=\u001b[39m val_datagen\u001b[39m.\u001b[39mflow_from_directory(\n\u001b[0;32m     23\u001b[0m     test_data_dir,\n\u001b[0;32m     24\u001b[0m     target_size\u001b[39m=\u001b[39m(img_width, img_height),\n\u001b[0;32m     25\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m     26\u001b[0m     class_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PRINCE AYUSH\\.conda\\envs\\prince26ayush\\lib\\site-packages\\keras\\preprocessing\\image.py:1648\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1562\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflow_from_directory\u001b[39m(\n\u001b[0;32m   1563\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1564\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     keep_aspect_ratio\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1579\u001b[0m ):\n\u001b[0;32m   1580\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[0;32m   1581\u001b[0m \n\u001b[0;32m   1582\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1646\u001b[0m \u001b[39m            and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[0;32m   1647\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1648\u001b[0m     \u001b[39mreturn\u001b[39;00m DirectoryIterator(\n\u001b[0;32m   1649\u001b[0m         directory,\n\u001b[0;32m   1650\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1651\u001b[0m         target_size\u001b[39m=\u001b[39;49mtarget_size,\n\u001b[0;32m   1652\u001b[0m         color_mode\u001b[39m=\u001b[39;49mcolor_mode,\n\u001b[0;32m   1653\u001b[0m         keep_aspect_ratio\u001b[39m=\u001b[39;49mkeep_aspect_ratio,\n\u001b[0;32m   1654\u001b[0m         classes\u001b[39m=\u001b[39;49mclasses,\n\u001b[0;32m   1655\u001b[0m         class_mode\u001b[39m=\u001b[39;49mclass_mode,\n\u001b[0;32m   1656\u001b[0m         data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_format,\n\u001b[0;32m   1657\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1658\u001b[0m         shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1659\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[0;32m   1660\u001b[0m         save_to_dir\u001b[39m=\u001b[39;49msave_to_dir,\n\u001b[0;32m   1661\u001b[0m         save_prefix\u001b[39m=\u001b[39;49msave_prefix,\n\u001b[0;32m   1662\u001b[0m         save_format\u001b[39m=\u001b[39;49msave_format,\n\u001b[0;32m   1663\u001b[0m         follow_links\u001b[39m=\u001b[39;49mfollow_links,\n\u001b[0;32m   1664\u001b[0m         subset\u001b[39m=\u001b[39;49msubset,\n\u001b[0;32m   1665\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[0;32m   1666\u001b[0m         dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[0;32m   1667\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\PRINCE AYUSH\\.conda\\envs\\prince26ayush\\lib\\site-packages\\keras\\preprocessing\\image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[0;32m    562\u001b[0m     classes \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 563\u001b[0m     \u001b[39mfor\u001b[39;00m subdir \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(directory)):\n\u001b[0;32m    564\u001b[0m         \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    565\u001b[0m             classes\u001b[39m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'path/to/training/data'"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(img_width, img_height, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m               optimizer\u001b[39m=\u001b[39mAdam(lr\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m),\n\u001b[0;32m      4\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(\n\u001b[1;32m----> 8\u001b[0m     train_generator,\n\u001b[0;32m      9\u001b[0m     epochs\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m,\n\u001b[0;32m     10\u001b[0m     validation_data\u001b[39m=\u001b[39mval_generator,\n\u001b[0;32m     11\u001b[0m     callbacks\u001b[39m=\u001b[39m[tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)])\n\u001b[0;32m     13\u001b[0m \u001b[39m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     14\u001b[0m test_loss, test_acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(test_generator)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(test_generator)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Generate classification report and confusion matrix\u001b[39;00m\n\u001b[0;32m      2\u001b[0m target_names \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mnormal\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpre-cancerous\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcancerous\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(classification_report(y_true, y_pred, target_names\u001b[39m=\u001b[39mtarget_names))\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(confusion_matrix(y_true, y_pred))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate classification report and confusion matrix\n",
    "target_names = ['normal', 'pre-cancerous', 'cancerous']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prince26ayush",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb4d88182b05aeb8cd8247fd2b6a7c6a77d0006342efa6a01d184aae8331352d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
